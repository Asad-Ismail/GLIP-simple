{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test BertLayer inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "notebook_path = os.getcwd()\n",
    "project_path = os.path.join(notebook_path, '..')  \n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "import torch\n",
    "from model.glip import BertEncoderLayer,VLFuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 10\n",
    "hidden_size = 768\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, hidden_size)\n",
    "mask = torch.ones(batch_size, seq_len)\n",
    "\n",
    "encLayer = BertEncoderLayer(hidden_size=hidden_size)\n",
    "\n",
    "input = {\n",
    "    \"visual\": [torch.randn(batch_size, 256, 10, 10)],\n",
    "    \"visual_masks\": [torch.ones(batch_size, 10, 10)],\n",
    "    \"lang\": {\n",
    "        \"hidden\": x.clone(),\n",
    "        \"masks\": mask\n",
    "    }\n",
    "}\n",
    "\n",
    "y=encLayer(input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Shapes:\n",
      "Visual feature: [torch.Size([2, 256, 10, 10])]\n",
      "Language feature: torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInput Shapes:\")\n",
    "print (f\"Visual feature: {[f.shape for f in input['visual']]}\")\n",
    "print(f\"Language feature: {input['lang']['hidden'].shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['visual', 'visual_masks', 'lang'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(y['visual'][0],input['visual'][0])\n",
    "assert torch.allclose(y['visual_masks'][0],input['visual_masks'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['lang']['hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.allclose(y['lang']['hidden'],input['lang']['hidden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLFuse Test Results:\n",
      "\n",
      "Input Shapes:\n",
      "Visual feature: [torch.Size([2, 256, 10, 10])]\n",
      "Language feature: torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_dim= 256\n",
    "# Test VLFuse module\n",
    "vlfuse = VLFuse(hidden_dim=hidden_dim)\n",
    "\n",
    "# Forward pass\n",
    "outputs = vlfuse(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shapes\n",
      "Visual feature: [torch.Size([2, 256, 10, 10])]\n",
      "Language feature: torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Output shapes\")\n",
    "print (f\"Visual feature: {[f.shape for f in outputs['visual']]}\")\n",
    "print(f\"Language feature: {outputs['lang']['hidden'].shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_changes = [(out - inp).abs().mean().item() for out, inp in zip(outputs['visual'], input['visual'])]\n",
    "lang_change = (outputs['lang']['hidden'] - input['lang']['hidden']).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Changes (L1 norm):\n",
      "Visual level 0 change: 0.062\n",
      "Language feature change: 0.015\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature Changes (L1 norm):\")\n",
    "for i, change in enumerate(visual_changes):\n",
    "    print(f\"Visual level {i} change: {change:.3f}\")\n",
    "print(f\"Language feature change: {lang_change:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
